# PhÃ¢n tÃ­ch táº¡i sao accuracy giáº£m khi thÃªm Anchor Routing

## ğŸ”´ Lá»—i nghiÃªm trá»ng: THÃŠM `.mean(0)` khÃ´ng cÃ³ trong code gá»‘c

### **So sÃ¡nh code gá»‘c vs code cÃ³ anchor:**

#### **1. Test Mode:**

**Code gá»‘c:**

```python
rsamples = qdist.rsample([self.forward_times])  # [forward_times, n_classes, D]
text_features_ = text_features_.unsqueeze(0).expand(self.forward_times, -1, -1)  # [forward_times, n_classes, D]
text_features_ = rsamples + text_features_  # [forward_times, n_classes, D]
logits_ = logit_scale * image_features_normed @ text_features_.permute(0, 2, 1)  # [B, forward_times, n_classes]
logits.append(logits_)  # âŒ KHÃ”NG cÃ³ .mean(0)
```

**Code cÃ³ anchor (SAI):**

```python
n_samples_task = int(alloc[i].item())  # CÃ³ thá»ƒ khÃ¡c forward_times
rsamples = qdist.rsample([n_samples_task])  # [n_samples_task, n_classes, D]
text_features_ = text_features_.unsqueeze(0).expand(n_samples_task, -1, -1)  # [n_samples_task, n_classes, D]
text_features_ = rsamples + text_features_  # [n_samples_task, n_classes, D]
logits_ = logit_scale * image_features_normed @ text_features_.permute(0, 2, 1)  # [B, n_samples_task, n_classes]
logits_ = logits_.mean(0, keepdim=True)  # âŒ THÃŠM DÃ’NG NÃ€Y KHÃ”NG CÃ“ TRONG CODE Gá»C!
logits.append(logits_)
```

#### **2. Training Mode:**

**Code gá»‘c:**

```python
rsamples = qdist.rsample([self.forward_times])  # [forward_times, n_classes, D]
text_features_ = text_features_.unsqueeze(0).expand(self.forward_times, -1, -1)  # [forward_times, n_classes, D]
text_features_ = rsamples + text_features_  # [forward_times, n_classes, D]
logits_ = (logit_scale * image_features_normed @ text_features_.permute(0, 2, 1))  # [B, forward_times, n_classes]
logits.append(logits_)  # âŒ KHÃ”NG cÃ³ .mean(0)
```

**Code cÃ³ anchor (SAI):**

```python
n_samples_task = int(alloc[i].item())  # CÃ³ thá»ƒ khÃ¡c forward_times
rsamples = qdist.rsample([n_samples_task])  # [n_samples_task, n_classes, D]
text_features_ = text_features_.unsqueeze(0).expand(n_samples_task, -1, -1)  # [n_samples_task, n_classes, D]
text_features_ = rsamples + text_features_  # [n_samples_task, n_classes, D]
logits_ = (logit_scale * image_features_normed @ text_features_.permute(0, 2, 1))  # [B, n_samples_task, n_classes]
logits_ = logits_.mean(0, keepdim=True)  # âŒ THÃŠM DÃ’NG NÃ€Y KHÃ”NG CÃ“ TRONG CODE Gá»C!
logits.append(logits_)
```

---

## ğŸ”´ Váº¥n Ä‘á» chÃ­nh:

### **1. Code gá»‘c KHÃ”NG cÃ³ `.mean(0)` trÆ°á»›c khi append:**

Trong code gá»‘c, `logits_` cÃ³ shape `[B, forward_times, n_classes]` vÃ  Ä‘Æ°á»£c append trá»±c tiáº¿p vÃ o list `logits`.

Sau Ä‘Ã³, khi `torch.cat(logits, -1)`, nÃ³ sáº½ concat theo chiá»u class, táº¡o ra shape `[B, forward_times, total_classes]`.

Cuá»‘i cÃ¹ng, trong code gá»‘c cÃ³ thá»ƒ cÃ³ `.mean(0)` á»Ÿ Ä‘Ã¢u Ä‘Ã³, hoáº·c cÃ³ thá»ƒ khÃ´ng.

**NhÆ°ng quan trá»ng:** Code gá»‘c giá»¯ nguyÃªn shape `[B, forward_times, n_classes]` cho má»—i task.

### **2. Code cÃ³ anchor THÃŠM `.mean(0)` sá»›m:**

Khi thÃªm `.mean(0, keepdim=True)`, shape cá»§a `logits_` trá»Ÿ thÃ nh `[1, n_classes]` (hoáº·c `[B, n_classes]` náº¿u khÃ´ng cÃ³ keepdim).

**Váº¥n Ä‘á»:**

- Code gá»‘c: `logits_` shape `[B, forward_times, n_classes]` â†’ sau khi cat: `[B, forward_times, total_classes]`
- Code cÃ³ anchor: `logits_` shape `[1, n_classes]` (hoáº·c `[B, n_classes]`) â†’ sau khi cat: `[1, total_classes]` hoáº·c `[B, total_classes]`

**Äiá»u nÃ y lÃ m thay Ä‘á»•i hoÃ n toÃ n cÃ¡ch tÃ­nh toÃ¡n!**

### **3. Váº¥n Ä‘á» vá» sá»‘ lÆ°á»£ng samples khÃ¡c nhau:**

Khi dÃ¹ng anchor routing, má»—i task cÃ³ sá»‘ samples khÃ¡c nhau (`n_samples_task`). Äiá»u nÃ y cÃ³ nghÄ©a:

- Task 0: 15 samples
- Task 1: 3 samples
- Task 2: 2 samples

Khi tÃ­nh `.mean(0)` trÃªn cÃ¡c samples khÃ¡c nhau, trá»ng sá»‘ cá»§a má»—i task sáº½ khÃ¡c nhau, dáº«n Ä‘áº¿n káº¿t quáº£ khÃ´ng cÃ´ng báº±ng.

---

## âœ… Giáº£i phÃ¡p:

### **Option 1: Loáº¡i bá» `.mean(0)` Ä‘á»ƒ giá»‘ng code gá»‘c**

```python
# Test mode (dÃ²ng 427-433)
logits_ = logit_scale * image_features_normed @ text_features_.permute(0, 2, 1)
# XÃ“A dÃ²ng nÃ y: logits_ = logits_.mean(0, keepdim=True)
logits.append(logits_)

# Training mode (dÃ²ng 577-596)
logits_ = (logit_scale * image_features_normed @ text_features_.permute(0, 2, 1))
# XÃ“A dÃ²ng nÃ y: logits_ = logits_.mean(0, keepdim=True)
logits.append(logits_)
```

Sau Ä‘Ã³, á»Ÿ cuá»‘i forward function, tÃ­nh mean náº¿u cáº§n:

```python
logits = torch.cat(logits, -1)  # [B, n_samples_varies, total_classes]
logits = logits.mean(1)  # Mean over samples dimension
```

### **Option 2: Giá»¯ `.mean(0)` nhÆ°ng Ä‘áº£m báº£o táº¥t cáº£ task cÃ³ cÃ¹ng sá»‘ samples**

Náº¿u muá»‘n giá»¯ `.mean(0)`, pháº£i Ä‘áº£m báº£o táº¥t cáº£ task cÃ³ cÃ¹ng sá»‘ samples, hoáº·c normalize theo sá»‘ samples.

### **Option 3: Äiá»u chá»‰nh allocation Ä‘á»ƒ tá»•ng samples khÃ´ng Ä‘á»•i**

Thay vÃ¬ phÃ¢n bá»• samples theo weights, giá»¯ tá»•ng sá»‘ samples = `forward_times * num_tasks` vÃ  phÃ¢n bá»• Ä‘á»u hÆ¡n.

---

## ğŸ” NguyÃªn nhÃ¢n chÃ­nh xÃ¡c:

**Accuracy giáº£m vÃ¬:**

1. **ThÃªm `.mean(0)` sá»›m** â†’ Thay Ä‘á»•i cÃ¡ch tÃ­nh toÃ¡n, máº¥t thÃ´ng tin vá» variance giá»¯a cÃ¡c samples
2. **Sá»‘ samples khÃ¡c nhau** â†’ Má»—i task cÃ³ trá»ng sá»‘ khÃ¡c nhau khi tÃ­nh mean, khÃ´ng cÃ´ng báº±ng
3. **Shape khÃ´ng Ä‘Ãºng** â†’ Khi cat logits, shape khÃ´ng match vá»›i code gá»‘c

**Giáº£i phÃ¡p Ä‘Æ¡n giáº£n nháº¥t:** XÃ³a `.mean(0, keepdim=True)` á»Ÿ cáº£ test vÃ  training mode Ä‘á»ƒ giá»‘ng code gá»‘c.
